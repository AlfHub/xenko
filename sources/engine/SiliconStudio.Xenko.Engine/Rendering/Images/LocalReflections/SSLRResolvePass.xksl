// Copyright (c) 2017 Silicon Studio Corp. (http://siliconstudio.co.jp)
// This file is distributed under GPL v3. See LICENSE.md for details.

namespace SiliconStudio.Xenko.Rendering.Images
{
    /// <summary>
	/// Screen Space Local Reflections shader for Resolve Pass
    /// </summary>
    shader SSLRResolvePass : ImageEffectShader, SSLRCommon, NormalPack, Math, BRDFMicrofacet
    {
		// Parmeter to control minimum Z of view space normal of the pixel to be used in SSR
		#define SSR_MIN_Z_REFLECT 0.1f

        // TODO: move this to lib or sth
        float RandN(float2 pos, float2 random)
        {
	        return frac(sin(dot(pos.xy + random, float2(12.9898, 78.233))) * 43758.5453);

        }

        float2 RandN2(float2 pos, float2 random)
        {
	        return frac(sin(dot(pos.xy + random, float2(12.9898, 78.233))) * float2(43758.5453, 28001.8384));
        }

        float RandS(float2 pos, float2 random)
        {
	        return RandN(pos, random) * 2.0 - 1.0;
        }

        // [Jimenez 2014] "Next Generation Post Processing In Call Of Duty Advanced Warfare"  
        float InterleavedGradientNoise (float2 pos, float2 random)
        {
	        float3 magic = float3(0.06711056, 0.00583715, 52.9829189);
	        return frac(magic.z * frac(dot(pos.xy + random, magic.xy)));
        }


        // https://www.shadertoy.com/view/4sBSDW
        float Step1(float2 uv,float n)
        {
	        float 
	        a = 1.0,
	        b = 2.0,
	        c = -12.0,
	        t = 1.0;
		   
	        return (1.0/(a*4.0+b*4.0-c))*(
			          RandS(uv+float2(-1.0,-1.0)*t,n)*a+
			          RandS(uv+float2( 0.0,-1.0)*t,n)*b+
			          RandS(uv+float2( 1.0,-1.0)*t,n)*a+
			          RandS(uv+float2(-1.0, 0.0)*t,n)*b+
			          RandS(uv+float2( 0.0, 0.0)*t,n)*c+
			          RandS(uv+float2( 1.0, 0.0)*t,n)*b+
			          RandS(uv+float2(-1.0, 1.0)*t,n)*a+
			          RandS(uv+float2( 0.0, 1.0)*t,n)*b+
			          RandS(uv+float2( 1.0, 1.0)*t,n)*a+
			         0.0);
        }

        float Step2(float2 uv,float n)
        {
	        float a=1.0,b=2.0,c=-2.0,t=1.0;   
	        return (4.0/(a*4.0+b*4.0-c))*(
			          Step1(uv+float2(-1.0,-1.0)*t,n)*a+
			          Step1(uv+float2( 0.0,-1.0)*t,n)*b+
			          Step1(uv+float2( 1.0,-1.0)*t,n)*a+
			          Step1(uv+float2(-1.0, 0.0)*t,n)*b+
			          Step1(uv+float2( 0.0, 0.0)*t,n)*c+
			          Step1(uv+float2( 1.0, 0.0)*t,n)*b+
			          Step1(uv+float2(-1.0, 1.0)*t,n)*a+
			          Step1(uv+float2( 0.0, 1.0)*t,n)*b+
			          Step1(uv+float2( 1.0, 1.0)*t,n)*a+
			         0.0);
        }

        float3 Step3T(float2 uv, float time)
        {
	        float a=Step2(uv, 0.07*(frac(time)+1.0));    
	        float b=Step2(uv, 0.11*(frac(time)+1.0));    
	        float c=Step2(uv, 0.13*(frac(time)+1.0));
	        return float3(a,b,c);
        }





        float4 TangentToWorld(float3 N, float4 H)
        {
	        float3 UpVector = abs(N.z) < 0.999 ? float3(0.0, 0.0, 1.0) : float3(1.0, 0.0, 0.0);
	        float3 T = normalize( cross( UpVector, N ) );
	        float3 B = cross( N, T );
				 
	        return float4((T * H.x) + (B * H.y) + (N * H.z), H.w);
        }

        // Brian Karis, Epic Games "Real Shading in Unreal Engine 4"
        float4 ImportanceSampleGGX(float2 Xi, float Roughness)
        {
	        float m = Roughness * Roughness;
	        float m2 = m * m;
		
	        float Phi = 2 * PI * Xi.x;
				 
	        float CosTheta = sqrt((1.0 - Xi.y) / (1.0 + (m2 - 1.0) * Xi.y));
	        float SinTheta = sqrt(max(1e-5, 1.0 - CosTheta * CosTheta));
				 
	        float3 H;
	        H.x = SinTheta * cos(Phi);
	        H.y = SinTheta * sin(Phi);
	        H.z = CosTheta;
		
	        float d = (CosTheta * m2 - CosTheta) * CosTheta + 1;
	        float D = m2 / (PI * d * d);
	        float pdf = D * CosTheta;

	        return float4(H, pdf); 
        }

        float BRDF_Unity_Weight(float3 V, float3 L, float3 N, float Roughness)
        {
            float3 H = normalize(L + V);

            float NdotH = saturate(dot(N,H));
            float NdotL = saturate(dot(N,L));
            float NdotV = saturate(dot(N,V));

            half G = VisibilitySmithGGXCorrelated(Roughness, NdotL, NdotV);
            half D = NormalDistributionGGX(Roughness, NdotH);

            return (D * G) * (PI / 4.0);
        }



        static const float2 offset[4] =
{
	float2(0, 0),
	float2(2, -2),
	float2(-2, -2),
	float2(0, 2)
};






        override stage float4 Shading()
        {
			// Inputs Mapping:
			// Texture0 - Scene Color (with blurred mip maps chain)
			// Texture1 - Depth
			// Texture2 - World Space Normals
			// Texture3 - Specular Color + Roughness
            // Texture4 - Blue Noise
			// Texture5 - Ray Trace result
			// Texture6 - Ray Trace Mask result

			float2 uv = streams.TexCoord;
			
            if(Texture6.SampleLevel(LinearSampler, uv, 0).r <= 0.0001)
                return 0;
            
			// Sample material roughness
			float4 specularRoughnessBuffer = Texture3.SampleLevel(PointSampler, uv, 0);
			float roughness = specularRoughnessBuffer.a;
			
			// Get view space position
			float depth = SampleZ(uv);
			float3 positionVS = ComputeViewPosition(uv, depth);
			
            //return float4(uv, 1, 1);
            //return float4(Texture6.SampleLevel(LinearSampler, uv, 0).r, 1, 1, 1);
            //return pow(depth.xxxx, 8) / 6;

			// Reject invalid pixels
			if(positionVS.z > 100.0f || roughness > RoughnessFade)
				return 0;

			// Calculate view space normal vector
			float4 normalsBuffer = Texture2.SampleLevel(PointSampler, uv, 0);
			float3 normalWS = DecodeNormal(normalsBuffer.rgb);
			float3 normalVS = mul(normalWS, (float3x3)V);
			
            float3 positionWS = ComputeWorldPosition(uv, depth);
			float3 viewWS = normalize(positionWS - CameraPosWS.xyz);
			float3 reflectWS = reflect(viewWS, normalWS);
			
			// TODO: dont use reflectVS, only reflectWS ??
			
            float2 random = RandN2(uv, Time * UseTemporal);
            
            //return float4(random, 0, 1);

            // Blue noise generated by https://github.com/bartwronski/BlueNoiseGenerator/
            //float2 jitter = Texture4.SampleLevel(LinearSampler, float2(uv + random), 0).rg;
            //float2 jitter = Texture4.SampleLevel(LinearSampler, uv, 0).rg;
            //float2 jitter = random;
		    //float2 Xi = jitter;
		    //Xi.y = lerp(Xi.y, 0.0, BRDFBias);

            float2 blueNoise = random.xy * 2.0 - 1.0; // TODO: use blue noise texture
            //float2 blueNoise = Texture4.SampleLevel(LinearSampler, uv + random, 0).rg * 2.0 - 1.0; // works better with [-1, 1] range

            float2x2 offsetRotationMatrix = float2x2(blueNoise.x, blueNoise.y, -blueNoise.y, blueNoise.x);

            int NumResolve = 4; // TODO: use param

            float NdotV = saturate(dot(normalWS, -viewWS));
		    float coneTangent = lerp(0.0, roughness * (1.0 - BRDFBias), pow(NdotV, 1.5) * sqrt(roughness));

		    float maxMipLevel = (float)MaxColorMiplevel;// - 1.0;

            float3 vectorV = normalize(-positionVS);

            //return float4(1, 0, 1, 1);

		    float4 result = 0.0;
            float weightSum = 0.0;	
            for(int i = 0; i < NumResolve; i++)
            {
                float2 offsetUV = offset[i] * SSRtexelSize;
                offsetUV =  mul(offsetRotationMatrix, offsetUV);

                // "uv" is the location of the current (or "local") pixel. We want to resolve the local pixel using
                // intersections spawned from neighboring pixels. The neighboring pixel is this one:
                float2 neighborUv = uv + offsetUV;

                // Now we fetch the intersection point and the PDF that the neighbor's ray hit.
                float4 hitPacked = Texture5.SampleLevel(LinearSampler, neighborUv, 0); // TODO: test with PointSampler
                float2 hitUv = hitPacked.xy;
                float hitZ = hitPacked.z;
                float hitPDF = hitPacked.w;
                float hitMask = Texture6.SampleLevel(LinearSampler, neighborUv, 0).r;

                float3 hitViewPos = ScreenToView(hitUv, hitZ);

                //return float4(hitViewPos, 1);

                // We assume that the hit point of the neighbor's ray is also visible for our ray, and we blindly pretend
                // that the current pixel shot that ray. To do that, we treat the hit point as a tiny light source. To calculate
                // a lighting contribution from it, we evaluate the BRDF. Finally, we need to account for the probability of getting
                // this specific position of the "light source", and that is approximately 1/PDF, where PDF comes from the neighbor.
                // Finally, the weight is BRDF/PDF. BRDF uses the local pixel's normal and roughness, but PDF comes from the neighbor.
                //float weight = BRDF_Unity_Weight(vectorV /*V*/, normalize(hitViewPos - positionVS) /*L*/, normalVS /*N*/, roughness) / max(1e-5, hitPDF);
                float weight = 1.0f;
                
                //return float4(weight.xxx, 1);

                float intersectionCircleRadius = coneTangent * length(hitUv - uv);
                float mip = clamp(log2(intersectionCircleRadius * TraceSizeMax), 0.0, maxMipLevel); // TODO; rename TraceSizeMax to ResolveSizeMax

                float4 sampleColor = float4(Texture0.SampleLevel(LinearSampler, hitUv, mip).rgb, hitMask);
                
                //if(_Fireflies == 1) // TODO: use param for Fireflies
                //    sampleColor.rgb /= 1 + Luminance(sampleColor.rgb);

                result += sampleColor * weight;
                weightSum += weight;
            }
            result /= weightSum;
            result.rgb *= result.a;

		    //if(_Fireflies == 1) // TODO: use param for Fireflies
			//    result.rgb /= 1 - Luminance(result.rgb);

            
    	    return max(1e-5, result);
        }
    };
}